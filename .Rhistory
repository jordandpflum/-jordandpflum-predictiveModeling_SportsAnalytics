#b. Based upon the significance codes of the summary we can reject
#zn, dis, rad, black and medv for the null hypothesis
#
model = lm(crim~., data=Boston)
print(summary(model))
#C. The multiple linear regression seems to capture more of the interaction
# than simple linear regression with each predictor. There is a lower residual
#standard error and better adjusted r-squared
coeff=c()
for (i in 1:length(models)) {
coeff=c(coeff, models[[i]]$coef[2])
}
coefMulti=model$coef[2:14]
plot(coeff, coefMulti, xlab="Coefficients from univariate regression",
ylab="Coefficients from multiple regression ")
#D. For most predictors there is evidence of non-linear association however for
#predictor such as black that has an extremely high p-value for quadratic and
#cubic there isn't evidence for non-linear association. Some predictors do
#have high p-value for cubic but not quadratic which suggests some non-linear
#association
for (i in seq(along=cols)){
if(cols[i] != 'chas'){
print(cols[i])
formula = as.formula(paste("crim ~ poly(",cols[i],",3)", collapse="", sep=""))
nonlinear = lm(formula, data=Boston)
print(summary(nonlinear))
}
}
#Chapter 6 Problem 9
#a.
library(ISLR)
set.seed(123)
n = dim(College)[1]
ind = sample(1:n, size=n*.8, replace=FALSE)
train = College[ind,]
test = College[-ind,]
#b.
Collegemodel = lm(Apps~., data=train)
Collegepred = predict(Collegemodel, test)
RMSE=sqrt(mean((Collegepred - test[, "Apps"] )^2))
print(RMSE)
#c.
library(glmnet)
#cv.glmnet expects matrix of predictors so using model.matrix
trainMatrix = model.matrix(Apps~., data=train)
testMatrix = model.matrix(Apps~., data=test)
grid = 10 ^ seq(10, -2, length=100)
set.seed(123)
ridgeModel = cv.glmnet(trainMatrix, train[, "Apps"], alpha=0, lambda=grid, thresh=1e-12)
lambdaBest = ridgeModel$lambda.min
ridgePred=predict(ridgeModel,s=lambdaBest ,newx=testMatrix)
RMSERidge=sqrt(mean((ridgePred-test[, "Apps"])^2))
print(RMSERidge)
#d.
set.seed(123)
lassoModel = cv.glmnet(trainMatrix, train[, "Apps"], alpha=1, lambda=grid, thresh=1e-12)
lambdaBestLasso = lassoModel$lambda.min
lassoPred=predict(lassoModel,s=lambdaBestLasso ,newx=testMatrix)
RMSELasso=sqrt(mean((lassoPred-test[, "Apps"])^2))
print(RMSELasso)
lassoCoef=predict(lassoModel,type="coefficients",s=lambdaBestLasso)
#14 of the 19 coefficients are non-zero
print(length(lassoCoef[lassoCoef!=0]))
#e.
set.seed(123)
pcrModel = pcr(Apps~., data=train, scale=TRUE, validation="CV")
summary(pcrModel)
#Lowest adjCV is at 17 so M=17
predPCR = predict(pcrModel, test, ncomp=17)
RMSEPCR=sqrt(mean((predPCR-test[, "Apps"])^2))
print(RMSEPCR)
#f
set.seed(123)
plsModel = plsr(Apps~., data=train, scale=TRUE, validation="CV")
summary(plsModel)
#Lowest adjCV levels around 6-17 so pick 9 at random so M=9
predPLS = predict(plsModel, test, ncomp=9)
RMSEPLS=sqrt(mean((predPLS-test[, "Apps"])^2))
print(RMSEPLS)
#g
#It looks like all models are about the same RMSE, however RIDGE has highest RMSE
#The mean Apps is around 3000 and with RMSE at around 1500, we cannot precisely
#predict the college applications for a school
RMSE_ALL = c(RMSE, RMSERidge, RMSELasso, RMSEPCR, RMSEPLS)
barplot(RMSE_ALL, names.arg=c("Least Squares", "RIDGE", "LASSO", "PCR", "PLS"), col = "darkred")
#Chapter 6 problem 11
#a.
#cv.glmnet expects matrix of predictors so using model.matrix
set.seed(123)
n = dim(Boston)[1]
ind = sample(1:n, size=n*.8, replace=FALSE)
train = Boston[ind,]
test = Boston[-ind,]
#RIDGE
trainMatrix = model.matrix(crim~., data=train)
testMatrix = model.matrix(crim~., data=test)
grid = 10 ^ seq(10, -2, length=100)
ridgeModel = cv.glmnet(trainMatrix, train[, "crim"], alpha=0, lambda=grid, thresh=1e-12)
lambdaBest = ridgeModel$lambda.min
ridgePred=predict(ridgeModel,s=lambdaBest ,newx=testMatrix)
RMSERidge=sqrt(mean((ridgePred-test[, "crim"])^2))
print(RMSERidge)
#LASSO
lassoModel = cv.glmnet(trainMatrix, train[, "crim"], alpha=1, lambda=grid, thresh=1e-12)
lambdaBestLasso = lassoModel$lambda.min
lassoPred=predict(lassoModel,s=lambdaBestLasso ,newx=testMatrix)
RMSELasso=sqrt(mean((lassoPred-test[, "crim"])^2))
print(RMSELasso)
#PCR
pcrModel = pcr(crim~., data=train, scale=TRUE, validation="CV")
summary(pcrModel)
#Lowest adjCV is at 13 so M=13
predPCR = predict(pcrModel, test, ncomp=13)
RMSEPCR=sqrt(mean((predPCR-test[, "crim"])^2))
print(RMSEPCR)
set.seed(123)
n = dim(Boston)[1]
ind = sample(1:n, size=n*.5, replace=FALSE)
train = Boston[ind,]
test = Boston[-ind,]
#RIDGE
trainMatrix = model.matrix(crim~., data=train)
testMatrix = model.matrix(crim~., data=test)
grid = 10 ^ seq(10, -2, length=100)
ridgeModel = cv.glmnet(trainMatrix, train[, "crim"], alpha=0, lambda=grid, thresh=1e-12)
lambdaBest = ridgeModel$lambda.min
ridgePred=predict(ridgeModel,s=lambdaBest ,newx=testMatrix)
RMSERidge=sqrt(mean((ridgePred-test[, "crim"])^2))
print(RMSERidge)
#LASSO
lassoModel = cv.glmnet(trainMatrix, train[, "crim"], alpha=1, lambda=grid, thresh=1e-12)
lambdaBestLasso = lassoModel$lambda.min
lassoPred=predict(lassoModel,s=lambdaBestLasso ,newx=testMatrix)
RMSELasso=sqrt(mean((lassoPred-test[, "crim"])^2))
print(RMSELasso)
#PCR
pcrModel = pcr(crim~., data=train, scale=TRUE, validation="CV")
summary(pcrModel)
#Lowest adjCV is at 13 so M=13
predPCR = predict(pcrModel, test, ncomp=13)
RMSEPCR=sqrt(mean((predPCR-test[, "crim"])^2))
print(RMSEPCR)
set.seed(123)
n = dim(Boston)[1]
ind = sample(1:n, size=n*.8, replace=FALSE)
train = Boston[ind,]
test = Boston[-ind,]
#RIDGE
trainMatrix = model.matrix(crim~., data=train)
testMatrix = model.matrix(crim~., data=test)
grid = 10 ^ seq(10, -2, length=100)
ridgeModel = cv.glmnet(trainMatrix, train[, "crim"], alpha=0, lambda=grid, thresh=1e-12)
lambdaBest = ridgeModel$lambda.min
ridgePred=predict(ridgeModel,s=lambdaBest ,newx=testMatrix)
RMSERidge=sqrt(mean((ridgePred-test[, "crim"])^2))
print(RMSERidge)
#LASSO
lassoModel = cv.glmnet(trainMatrix, train[, "crim"], alpha=1, lambda=grid, thresh=1e-12)
lambdaBestLasso = lassoModel$lambda.min
lassoPred=predict(lassoModel,s=lambdaBestLasso ,newx=testMatrix)
RMSELasso=sqrt(mean((lassoPred-test[, "crim"])^2))
print(RMSELasso)
#PCR
pcrModel = pcr(crim~., data=train, scale=TRUE, validation="CV")
summary(pcrModel)
#Lowest adjCV is at 13 so M=13
predPCR = predict(pcrModel, test, ncomp=13)
RMSEPCR=sqrt(mean((predPCR-test[, "crim"])^2))
print(RMSEPCR)
library(leaps)
subsetModel <- regsubsets(crim ~ ., data=train,nvmax=dim(Boston)[2])
lm.best.coef <- coef(subsetModel,id=which.min(summary(subsetModel)$bic))
subsetModel <- regsubsets(crim ~ ., data=train,nvmax=dim(Boston)[2])
summary(subsetModel)
summary(subsetModel$rss)
summary(subsetModel$rsq)
set.seed(123)
Boston=na.omit(Boston)
n = dim(Boston)[1]
ind = sample(1:n, size=n*.8, replace=FALSE)
train = Boston[ind,]
test = Boston[-ind,]
#Best Subset Selection
subsetModel <- regsubsets(crim ~ ., data=train,nvmax=dim(Boston)[2])
summary(subsetModel$rsq)
library(MASS)
attach(Boston)
sum(is.na(Boston$Salary))
summary(subsetModel)
subsetModel <- regsubsets(crim ~ ., data=train,nvmax=dim(Boston)[2])
sumi=summary(subsetModel)
sumi$rsq
sumi$rss
k=10
for(j in 1:k){
subsetModel=regsubsets(crim~.,data = Boston[folds!=j,], nvmax=dim(Boston)[2])
for(i in 1:dim(Boston)[2]){
pred=predict(subsetModel, Boston[folds==j,],id=i)
# Get the mean squared error for the model trained on the fold with the subset
cv.errors[j,i]=mean((Boston$crim[folds==j]-pred)^2)
}
}
subsetModel <- regsubsets(crim ~ ., data=train,nvmax=dim(Boston)[2])
errors = c()
for(i in 1:dim(Boston)[1]){
coefs=coef(subsetModel, id=i)
pred=testMatrix[, names(coefs)]%*%coefs
errors = c(errors, sqrt(mean((test$crim-pred)^2)))
}
subsetModel <- regsubsets(crim ~ ., data=train,nvmax=dim(Boston)[2])
errors = c()
for(i in 1:12){
coefs=coef(subsetModel, id=i)
pred=testMatrix[, names(coefs)]%*%coefs
errors = c(errors, sqrt(mean((test$crim-pred)^2)))
}
subsetModel <- regsubsets(crim ~ ., data=train,nvmax=dim(Boston)[2])
cols = dim(Boston)[2]
errors = c()
for(i in 1:cols){
coefs=coef(subsetModel, id=i)
pred=testMatrix[, names(coefs)]%*%coefs
errors = c(errors, sqrt(mean((test$crim-pred)^2)))
}
subsetModel <- regsubsets(crim ~ ., data=train,nvmax=dim(Boston)[2])
cols = dim(Boston)[2]-1
errors = c()
for(i in 1:cols){
coefs=coef(subsetModel, id=i)
pred=testMatrix[, names(coefs)]%*%coefs
errors = c(errors, sqrt(mean((test$crim-pred)^2)))
}
errors
min(errors)
#Chapter 3 Problem 15
#a. Based on the summary of each model it seems
#that all but chas are strong predictors that contribute
#per capita crime rate
set.seed(123)
cols = names(Boston)[-1]
models = vector('list',length(cols))
for (i in seq(along=cols)){
formula = as.formula(paste("crim ~ ",cols[i], collapse="", sep=""))
models[[i]] = lm(formula, data=Boston)
}
for (i in 1:length(models)) {
print(cols[i])
print(summary(models[[i]]))
}
#accessibility to radial highways and full-value property-tax rate have highest
#adjusted r-squared which can be seen in the plots as well
plot(rad, crim, xlab="rad", ylab="crim")
plot(tax, crim, xlab="tax", ylab="crim")
#b. Based upon the significance codes of the summary we can reject
#zn, dis, rad, black and medv for the null hypothesis
#
model = lm(crim~., data=Boston)
print(summary(model))
#C. The multiple linear regression seems to capture more of the interaction
# than simple linear regression with each predictor. There is a lower residual
#standard error and better adjusted r-squared
coeff=c()
for (i in 1:length(models)) {
coeff=c(coeff, models[[i]]$coef[2])
}
coefMulti=model$coef[2:14]
plot(coeff, coefMulti, xlab="Coefficients from univariate regression",
ylab="Coefficients from multiple regression ")
#D. For most predictors there is evidence of non-linear association however for
#predictor such as black that has an extremely high p-value for quadratic and
#cubic there isn't evidence for non-linear association. Some predictors do
#have high p-value for cubic but not quadratic which suggests some non-linear
#association
for (i in seq(along=cols)){
if(cols[i] != 'chas'){
print(cols[i])
formula = as.formula(paste("crim ~ poly(",cols[i],",3)", collapse="", sep=""))
nonlinear = lm(formula, data=Boston)
print(summary(nonlinear))
}
}
#Chapter 6 Problem 9
#a.
library(ISLR)
set.seed(123)
n = dim(College)[1]
ind = sample(1:n, size=n*.8, replace=FALSE)
train = College[ind,]
test = College[-ind,]
#b.
Collegemodel = lm(Apps~., data=train)
Collegepred = predict(Collegemodel, test)
RMSE=sqrt(mean((Collegepred - test[, "Apps"] )^2))
print(RMSE)
#c.
library(glmnet)
#cv.glmnet expects matrix of predictors so using model.matrix
trainMatrix = model.matrix(Apps~., data=train)
testMatrix = model.matrix(Apps~., data=test)
grid = 10 ^ seq(10, -2, length=100)
set.seed(123)
ridgeModel = cv.glmnet(trainMatrix, train[, "Apps"], alpha=0, lambda=grid, thresh=1e-12)
lambdaBest = ridgeModel$lambda.min
ridgePred=predict(ridgeModel,s=lambdaBest ,newx=testMatrix)
RMSERidge=sqrt(mean((ridgePred-test[, "Apps"])^2))
print(RMSERidge)
#d.
set.seed(123)
lassoModel = cv.glmnet(trainMatrix, train[, "Apps"], alpha=1, lambda=grid, thresh=1e-12)
lambdaBestLasso = lassoModel$lambda.min
lassoPred=predict(lassoModel,s=lambdaBestLasso ,newx=testMatrix)
RMSELasso=sqrt(mean((lassoPred-test[, "Apps"])^2))
print(RMSELasso)
lassoCoef=predict(lassoModel,type="coefficients",s=lambdaBestLasso)
#14 of the 19 coefficients are non-zero
print(length(lassoCoef[lassoCoef!=0]))
#e.
set.seed(123)
pcrModel = pcr(Apps~., data=train, scale=TRUE, validation="CV")
summary(pcrModel)
#Lowest adjCV is at 17 so M=17
predPCR = predict(pcrModel, test, ncomp=17)
RMSEPCR=sqrt(mean((predPCR-test[, "Apps"])^2))
print(RMSEPCR)
#f
set.seed(123)
plsModel = plsr(Apps~., data=train, scale=TRUE, validation="CV")
summary(plsModel)
#Lowest adjCV levels around 6-17 so pick 9 at random so M=9
predPLS = predict(plsModel, test, ncomp=9)
RMSEPLS=sqrt(mean((predPLS-test[, "Apps"])^2))
print(RMSEPLS)
#g
#It looks like all models are about the same RMSE, however RIDGE has highest RMSE
#The mean Apps is around 3000 and with RMSE at around 1500, we cannot precisely
#predict the college applications for a school
RMSE_ALL = c(RMSE, RMSERidge, RMSELasso, RMSEPCR, RMSEPLS)
barplot(RMSE_ALL, names.arg=c("Least Squares", "RIDGE", "LASSO", "PCR", "PLS"), col = "darkred")
#Chapter 6 problem 11
#a.
#cv.glmnet expects matrix of predictors so using model.matrix
set.seed(123)
Boston=na.omit(Boston)
n = dim(Boston)[1]
ind = sample(1:n, size=n*.8, replace=FALSE)
train = Boston[ind,]
test = Boston[-ind,]
trainMatrix = model.matrix(crim~., data=train)
testMatrix = model.matrix(crim~., data=test)
subsetModel <- regsubsets(crim ~ ., data=train,nvmax=dim(Boston)[2])
cols = dim(Boston)[2]-1
errors = c()
for(i in 1:cols){
coefs=coef(subsetModel, id=i)
pred=testMatrix[, names(coefs)]%*%coefs
errors = c(errors, sqrt(mean((test$crim-pred)^2)))
}
min(errors)
#Best Subset Selection
sumi=summary(subsetModel)
sumi$rss
#RIDGE
grid = 10 ^ seq(10, -2, length=100)
ridgeModel = cv.glmnet(trainMatrix, train[, "crim"], alpha=0, lambda=grid, thresh=1e-12)
lambdaBest = ridgeModel$lambda.min
ridgePred=predict(ridgeModel,s=lambdaBest ,newx=testMatrix)
RMSERidge=sqrt(mean((ridgePred-test[, "crim"])^2))
print(RMSERidge)
#LASSO
lassoModel = cv.glmnet(trainMatrix, train[, "crim"], alpha=1, lambda=grid, thresh=1e-12)
lambdaBestLasso = lassoModel$lambda.min
lassoPred=predict(lassoModel,s=lambdaBestLasso ,newx=testMatrix)
RMSELasso=sqrt(mean((lassoPred-test[, "crim"])^2))
print(RMSELasso)
#PCR
pcrModel = pcr(crim~., data=train, scale=TRUE, validation="CV")
summary(pcrModel)
#Lowest adjCV is at 13 so M=13
predPCR = predict(pcrModel, test, ncomp=13)
RMSEPCR=sqrt(mean((predPCR-test[, "crim"])^2))
print(RMSEPCR)
subsetModel <- regsubsets(crim ~ ., data=train,nvmax=dim(Boston)[2])
cols = dim(Boston)[2]-1
errors = c()
for(i in 1:cols){
coefs=coef(subsetModel, id=i)
print(coefs)
pred=testMatrix[, names(coefs)]%*%coefs
errors = c(errors, sqrt(mean((test$crim-pred)^2)))
}
min(errors)
subsetModel <- regsubsets(crim ~ ., data=train,nvmax=dim(Boston)[2])
cols = dim(Boston)[2]-1
errors = c()
for(i in 1:cols){
coefs=coef(subsetModel, id=i)
print(coefs)
pred=testMatrix[, names(coefs)]%*%coefs
errors = c(errors, sqrt(mean((test$crim-pred)^2)))
print(sqrt(mean((test$crim-pred)^2)))
print("\n")
}
min(errors)
(completeDataframe %>% filter(Year==2017, Player=="Clint Capela"))
rm(list=ls())
# Dataframe Creation
source("DataWrangling/createCompleteDataframe.R")
# Load Data (Player Salary)
playerSalaryData<-read.csv("Data/PlayerSalary_Season/salaries_1985to2018.csv", stringsAsFactors = FALSE)
# Load Data (Player Season Metrics)
playerSeasonMetricsData<-read.csv("Data/PlayerMetrics_Season/player_metric_season.csv", stringsAsFactors = FALSE)
completeDataframe <- createCompleteDataframeTotal(playerSalaryData=playerSalaryData,
playerSeasonMetricsData=playerSeasonMetricsData,
year_start=2010,
year_end=2017)
(completeDataframe %>% filter(Year==2017, Player=="Clint Capela"))
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
View(completeDataframe)
Clint_Capela = data.frame()
View(Clint_Capela)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
summary(completeDataframe$Salary)
std(completeDataframe$Salary)
summary(completeDataframe$Salary)
sd(completeDataframe$Salary)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
# Analysis
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
# Analysis
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
# Analysis
print(Boosting)
print(Boosting[0])
NULL
row.names(Boosting) = NULL
plot(Boosting)
Boosting
plot(Boosting)
plot(Boosting$var, Boosting$rel.inf)
plot(factor(Boosting$var), Boosting$rel.inf)
row.names(Boosting)=NULL
plot(factor(Boosting$var), Boosting$rel.inf)
plot(factor(Boosting$var), Boosting$rel.inf)
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
# Analysis
source("Prediction/predictions_based_on_position.R")
player_csv <- cleanPlayerSalary(completeDataframe)
# Analysis
