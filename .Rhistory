dummies.2 <- model.matrix(~pos)
dummies.2 <- dummies.2[,-c(1)]
edit$posC <- ifelse(edit[,1] == "C",1,0)
edit$tmATL <- ifelse(edit[,3] == "ATL",1,0)
edit <- cbind(edit,dummies.1)
edit <- cbind(edit,dummies.2)
edit <- edit[,-c(1,3)]
# try to compensate for overfit
#set.seed(1)
set.seed(2)
#set.seed(3)
train <- sample(1:nrow(edit),size = 250)
train.data <- edit[train,]
test.data <- edit[-train,]
model.1 <- lm(salary~.,data = train.data)
library(MASS)
steps1 <- stepAIC(model.1, direction = "both", k = 2)
# Fit MLR model
final.AIC <- lm(salary~Age + GS + MP + TRB_perc + STL_perc + BLK_perc + USG_perc +
OWS + DWS + OBPM + BPM + VORP + FG + FGA + X3P + X3PA + X3P_perc +
FT + FTA + DRB + AST + PF + tmATL + tmGSW + tmMIA + tmPOR +
tmUTA + posPG + tmDEN, data = train.data)
# Has an adjusted R-squared of 0.62
summary(final.AIC)
y.hat <- predict(final.AIC,newdata = test.data)
MSE.AIC <- mean((test.data$salary-y.hat)**2)
sqrt(MSE.AIC)
# Has only 5 variables, all high significance.
# Age, GS, FGA, DRB, PF
steps2 <- stepAIC(model.1, direction = "both", k = log(nrow(edit)))
# Fit MLR model
final.BIC <- lm(salary~Age + GS + USG_perc + BPM + VORP + FTA + DRB + AST +
PF + tmPOR, data = train.data)
summary(final.BIC)
# try to compensate for overfit
set.seed(1)
#set.seed(2)
#set.seed(3)
train <- sample(1:nrow(edit),size = 250)
train.data <- edit[train,]
test.data <- edit[-train,]
model.1 <- lm(salary~.,data = train.data)
library(MASS)
steps1 <- stepAIC(model.1, direction = "both", k = 2)
# Fit MLR model
final.AIC <- lm(salary~Age + GS + MP + TRB_perc + STL_perc + BLK_perc + USG_perc +
OWS + DWS + OBPM + BPM + VORP + FG + FGA + X3P + X3PA + X3P_perc +
FT + FTA + DRB + AST + PF + tmATL + tmGSW + tmMIA + tmPOR +
tmUTA + posPG + tmDEN, data = train.data)
# Has an adjusted R-squared of 0.62
summary(final.AIC)
y.hat <- predict(final.AIC,newdata = test.data)
MSE.AIC <- mean((test.data$salary-y.hat)**2)
sqrt(MSE.AIC)
# Has only 5 variables, all high significance.
# Age, GS, FGA, DRB, PF
steps2 <- stepAIC(model.1, direction = "both", k = log(nrow(edit)))
# Fit MLR model
final.BIC <- lm(salary~Age + GS + USG_perc + BPM + VORP + FTA + DRB + AST +
PF + tmPOR, data = train.data)
summary(final.BIC)
y.hat <- predict(final.BIC,newdata = test.data)
# Has only 5 variables, all high significance.
# Age, GS, FGA, DRB, PF
steps2 <- stepAIC(model.1, direction = "both", k = log(nrow(edit)))
summary(final.BIC)
summary(steps2)
y.hat <- predict(steps2,newdata = test.data)
MSE.BIC <- mean((test.data$salary-y.hat)**2)
sqrt(MSE.BIC)
# try to compensate for overfit
#set.seed(1)
#set.seed(2)
set.seed(3)
train <- sample(1:nrow(edit),size = 250)
train.data <- edit[train,]
test.data <- edit[-train,]
model.1 <- lm(salary~.,data = train.data)
library(MASS)
steps1 <- stepAIC(model.1, direction = "both", k = 2)
# Fit MLR model
final.AIC <- lm(salary~Age + GS + MP + TRB_perc + STL_perc + BLK_perc + USG_perc +
OWS + DWS + OBPM + BPM + VORP + FG + FGA + X3P + X3PA + X3P_perc +
FT + FTA + DRB + AST + PF + tmATL + tmGSW + tmMIA + tmPOR +
tmUTA + posPG + tmDEN, data = train.data)
# Has an adjusted R-squared of 0.62
summary(final.AIC)
y.hat <- predict(final.AIC,newdata = test.data)
MSE.AIC <- mean((test.data$salary-y.hat)**2)
sqrt(MSE.AIC)
# Has only 5 variables, all high significance.
# Age, GS, FGA, DRB, PF
steps2 <- stepAIC(model.1, direction = "both", k = log(nrow(edit)))
# Fit MLR model
final.BIC <- lm(salary~Age + GS + USG_perc + BPM + VORP + FTA + DRB + AST +
PF + tmPOR, data = train.data)
summary(final.BIC)
y.hat <- predict(final.BIC,newdata = test.data)
# try to compensate for overfit
#set.seed(1)
#set.seed(2)
#set.seed(3)
set.seed(4)
train <- sample(1:nrow(edit),size = 250)
train.data <- edit[train,]
test.data <- edit[-train,]
model.1 <- lm(salary~.,data = train.data)
library(MASS)
steps1 <- stepAIC(model.1, direction = "both", k = 2)
# Fit MLR model
final.AIC <- lm(salary~Age + GS + MP + TRB_perc + STL_perc + BLK_perc + USG_perc +
OWS + DWS + OBPM + BPM + VORP + FG + FGA + X3P + X3PA + X3P_perc +
FT + FTA + DRB + AST + PF + tmATL + tmGSW + tmMIA + tmPOR +
tmUTA + posPG + tmDEN, data = train.data)
# Has an adjusted R-squared of 0.62
summary(final.AIC)
y.hat <- predict(final.AIC,newdata = test.data)
MSE.AIC <- mean((test.data$salary-y.hat)**2)
sqrt(MSE.AIC)
# Has only 5 variables, all high significance.
# Age, GS, FGA, DRB, PF
steps2 <- stepAIC(model.1, direction = "both", k = log(nrow(edit)))
# Fit MLR model
final.BIC <- lm(salary~Age + GS + USG_perc + BPM + VORP + FTA + DRB + AST +
PF + tmPOR, data = train.data)
summary(final.BIC)
y.hat <- predict(final.BIC,newdata = test.data)
MSE.BIC <- mean((test.data$salary-y.hat)**2)
sqrt(MSE.BIC)
# try to compensate for overfit
#set.seed(1)
#set.seed(2)
#set.seed(3)
#set.seed(4)
set.seed(5)
train <- sample(1:nrow(edit),size = 250)
train.data <- edit[train,]
test.data <- edit[-train,]
model.1 <- lm(salary~.,data = train.data)
library(MASS)
steps1 <- stepAIC(model.1, direction = "both", k = 2)
# Fit MLR model
final.AIC <- lm(salary~Age + GS + MP + TRB_perc + STL_perc + BLK_perc + USG_perc +
OWS + DWS + OBPM + BPM + VORP + FG + FGA + X3P + X3PA + X3P_perc +
FT + FTA + DRB + AST + PF + tmATL + tmGSW + tmMIA + tmPOR +
tmUTA + posPG + tmDEN, data = train.data)
# Has an adjusted R-squared of 0.62
summary(final.AIC)
y.hat <- predict(final.AIC,newdata = test.data)
MSE.AIC <- mean((test.data$salary-y.hat)**2)
sqrt(MSE.AIC)
# Has only 5 variables, all high significance.
# Age, GS, FGA, DRB, PF
steps2 <- stepAIC(model.1, direction = "both", k = log(nrow(edit)))
# Fit MLR model
final.BIC <- lm(salary~Age + GS + USG_perc + BPM + VORP + FTA + DRB + AST +
PF + tmPOR, data = train.data)
summary(final.BIC)
y.hat <- predict(final.BIC,newdata = test.data)
MSE.BIC <- mean((test.data$salary-y.hat)**2)
sqrt(MSE.BIC)
rm(list = ls())
data <- read.csv("C:/Users/timot/Documents/Github/predictiveModelingSportsAnalytics/2017_player_salary_and_metrics.csv", header = T)
summary(data$salary)
rm(list = ls())
data <- read.csv("C:/Users/timot/Documents/Github/predictiveModelingSportsAnalytics/2017_player_salary_and_metrics.csv", header = T)
# ONLY LOOK AT STATS and remove columns that have no info
edit <- data[,c(6:53,58)]
rownames(edit) <- data$player_id
# Create dummy variable for each team/position
tm <- factor(edit$Tm)
pos <- factor(edit$Pos)
dummies.1 <- model.matrix(~tm)
dummies.1 <- dummies.1[,-c(1)]
dummies.2 <- model.matrix(~pos)
dummies.2 <- dummies.2[,-c(1)]
edit$posC <- ifelse(edit[,1] == "C",1,0)
edit$tmATL <- ifelse(edit[,3] == "ATL",1,0)
edit <- cbind(edit,dummies.1)
edit <- cbind(edit,dummies.2)
edit <- edit[,-c(1,3)]
# try to compensate for overfit
#set.seed(1)
#set.seed(2)
#set.seed(3)
#set.seed(4)
set.seed(5)
train <- sample(1:nrow(edit),size = 250)
train.data <- edit[train,]
test.data <- edit[-train,]
model.1 <- lm(salary~.,data = train.data)
library(MASS)
steps1 <- stepAIC(model.1, direction = "both", k = 2)
# Fit MLR model
final.AIC <- lm(salary~Age + GS + MP + TRB_perc + STL_perc + BLK_perc + USG_perc +
OWS + DWS + OBPM + BPM + VORP + FG + FGA + X3P + X3PA + X3P_perc +
FT + FTA + DRB + AST + PF + tmATL + tmGSW + tmMIA + tmPOR +
tmUTA + posPG + tmDEN, data = train.data)
# Has an adjusted R-squared of 0.62
summary(final.AIC)
y.hat <- predict(final.AIC,newdata = test.data)
MSE.AIC <- mean((test.data$salary-y.hat)**2)
sqrt(MSE.AIC)
# Has only 5 variables, all high significance.
# Age, GS, FGA, DRB, PF
steps2 <- stepAIC(model.1, direction = "both", k = log(nrow(edit)))
# Fit MLR model
final.BIC <- lm(salary~Age + GS + USG_perc + BPM + VORP + FTA + DRB + AST +
PF + tmPOR, data = train.data)
summary(final.BIC)
y.hat <- predict(final.BIC,newdata = test.data)
MSE.BIC <- mean((test.data$salary-y.hat)**2)
sqrt(MSE.BIC)
rm(list=ls())
# Dataframe Creation
source("DataWrangling/createCompleteDataframe.R")
setwd("C:/Users/timot/Docuemnts/GitHub/predictiveModelingSportsAnalytics/")
setwd("C:/Users/timot/Documents/GitHub/predictiveModelingSportsAnalytics/")
# Dataframe Creation
source("DataWrangling/createCompleteDataframe.R")
# Load Data (Player Salary)
playerSalaryData<-read.csv("Data/PlayerSalary_Season/salaries_1985to2018.csv", stringsAsFactors = FALSE)
# Load Data (Player Season Metrics)
playerSeasonMetricsData<-read.csv("Data/PlayerMetrics_Season/player_metric_season.csv", stringsAsFactors = FALSE)
completeDataframe <- createCompleteDataframeTotal(playerSalaryData=playerSalaryData,
playerSeasonMetricsData=playerSeasonMetricsData,
year_start=2010,
year_end=2017)
# Grouping by Age.
source("Classification/createAgeGroupingDataframe.R")
ageGroupedDataframe_18_22 <- createAgeGroupingDataframe(completeDataframe, ageGroup='18 - 22')
ageGroupedDataframe_23_26 <- createAgeGroupingDataframe(completeDataframe, ageGroup='23 - 26')
ageGroupedDataframe_27_30 <- createAgeGroupingDataframe(completeDataframe, ageGroup='27 - 30')
ageGroupedDataframe_31_35 <- createAgeGroupingDataframe(completeDataframe, ageGroup='31 - 35')
ageGroupedDataframe_over35 <- createAgeGroupingDataframe(completeDataframe, ageGroup='>35')
# Create X-DF
source("DataWrangling/createPartialDataframe.R")
variables = c("Pos", "Age", "G", "GS", "MP", "PTS", "AST", "TRB", "ORB", "DRB",
"STL", "BLK", "TOV", "PF", "FG", "FGA", "X2P", "X2PA", "X3P",
"FT", "FTA", "PER", "ORB_perc", "DRB_perc", "TRB_perc", "AST_perc",
"STL_perc", "BLK_perc", "TOV_perc", "USG_perc", "OWS", "DWS",
"WS", "WS_48", "OBPM", "DBPM", "BPM", "VORP", "TSA", "TS_perc",
"X3P_perc", "X2P_perc", "eFG_perc", "FT_perc")
library(kknn) ## knn library
library('fastDummies')
library(leaps)
library(docstring)
library(nnet)
library(randomForest)
library(gbm)
install.packages("randomForest")
install.packages("nnet")
install.packages("nnet")
rm(list=ls())
# Dataframe Creation
source("DataWrangling/createCompleteDataframe.R")
# Load Data (Player Salary)
playerSalaryData<-read.csv("Data/PlayerSalary_Season/salaries_1985to2018.csv", stringsAsFactors = FALSE)
# Load Data (Player Season Metrics)
playerSeasonMetricsData<-read.csv("Data/PlayerMetrics_Season/player_metric_season.csv", stringsAsFactors = FALSE)
completeDataframe <- createCompleteDataframeTotal(playerSalaryData=playerSalaryData,
playerSeasonMetricsData=playerSeasonMetricsData,
year_start=2010,
year_end=2017)
# Grouping by Age.
source("Classification/createAgeGroupingDataframe.R")
ageGroupedDataframe_18_22 <- createAgeGroupingDataframe(completeDataframe, ageGroup='18 - 22')
ageGroupedDataframe_23_26 <- createAgeGroupingDataframe(completeDataframe, ageGroup='23 - 26')
ageGroupedDataframe_27_30 <- createAgeGroupingDataframe(completeDataframe, ageGroup='27 - 30')
ageGroupedDataframe_31_35 <- createAgeGroupingDataframe(completeDataframe, ageGroup='31 - 35')
ageGroupedDataframe_over35 <- createAgeGroupingDataframe(completeDataframe, ageGroup='>35')
# Create X-DF
source("DataWrangling/createPartialDataframe.R")
variables = c("Pos", "Age", "G", "GS", "MP", "PTS", "AST", "TRB", "ORB", "DRB",
"STL", "BLK", "TOV", "PF", "FG", "FGA", "X2P", "X2PA", "X3P",
"FT", "FTA", "PER", "ORB_perc", "DRB_perc", "TRB_perc", "AST_perc",
"STL_perc", "BLK_perc", "TOV_perc", "USG_perc", "OWS", "DWS",
"WS", "WS_48", "OBPM", "DBPM", "BPM", "VORP", "TSA", "TS_perc",
"X3P_perc", "X2P_perc", "eFG_perc", "FT_perc")
xDF = createParitalDataframe(df = completeDataframe, colNames = variables)
colnames(xDF) <- variables
# Create Y-DF
variables = c("Salary")
yDF = createParitalDataframe(df = completeDataframe, colNames = variables)
yDF
summary(yDF)
boxplot(yDF)
plot(range(length((yDF))),yDF)
library(MASS)
# Dummy for position
pos <- factor(xDF$Pos)
model.1 <- model.matrix(~pos)[,-c(1)]
posC <- ifelse(xDF$Pos == "C",1,0)
pos.1 <- cbind(posC,model.1)
edit <- cbind(xDF,pos.1)[,-c(1)]
t.dta <- cbind(edit,yDF)
colnames(t.dta)[length(colnames(t.dta))] = "salary"
set.seed(40)
edit
t.dta
xDF
completeDataframe
dim(completeDataframe)
dim(t.dta)
t.dta <- cbind(edit,completeDataframe$salaryPercSalaryCap)
colnames(t.dta)[length(colnames(t.dta))] = "salary"
set.seed(40)
tr <- sample(1:nrow(edit),2400)
train <- t.dta[tr,]
test <- t.dta[-tr,]
model <- lm(salaryPercSalaryCap~.,data = train)
t.dta <- cbind(edit,completeDataframe$salaryPercSalaryCap)
colnames(t.dta)[length(colnames(t.dta))] = "salary"
set.seed(40)
tr <- sample(1:nrow(edit),2400)
train <- t.dta[tr,]
test <- t.dta[-tr,]
model <- lm(salaryPercSalaryCap~.,data = train)
steps <- stepAIC(model,direction = "both",k = log(nrow(t.dta)))
model
train
model <- lm(salary~.,data = train)
steps <- stepAIC(model,direction = "both",k = log(nrow(t.dta)))
summary(steps)
library(glmnet)
scaled <- scale(t.dta[,-c(58)])
scaled <- cbind(scaled,t.dta$salary)
tr.s <- scaled[tr,]
t.s <- scaled[-tr,]
lasso.model <- cv.glmnet(tr.s[,-c(58)],tr.s[,c(58)],alpha = 1 )
sqrt(lasso.model$cvm[lasso.model$lambda == lasso.model$lambda.1se])
# Plot lambdas
plot(log(lasso.model$lambda),sqrt(lasso.model$cvm),
main="LASSO CV (k=10)",xlab="log(lambda)",
ylab = "RMSE",col=4,type="b",cex.lab=1.2)
abline(v=log(lasso.model$lambda.1se),lty=2,col=2,lwd=2)
coefs.lasso <- predict(lasso.model, type = "coefficients", s = lasso.model$lambda.1se)
coefs.lasso
sqrt(lasso.model$cvm[lasso.model$lambda == lasso.model$lambda.1se])
lasso.model$cvm
y.hat <- predict(lasso.model,newdata = t.s)
t.s
t.dta
dim(t.dta)
t.dta[,59]
t.dta[,58]
colnames(t.dta)[58]
scaled <- scale(t.dta[,-c(58)])
scaled <- cbind(scaled,t.dta$salary)
tr.s <- scaled[tr,]
t.s <- scaled[-tr,]
t.s
colnames(t.s)
colnames(t.s)[58] <- "salary"
lasso.model <- cv.glmnet(tr.s[,-c(58)],tr.s[,c(58)],alpha = 1 )
y.hat <- predict(lasso.model,newdata = t.s)
y.hat <- predict(lasso.model,newdata = t.s[,-c(58)])
t,s
t.s
?predict
lasso.model
t.dta <- cbind(edit,completeDataframe$salaryPercSalaryCap)
colnames(t.dta)[length(colnames(t.dta))] = "salary"
set.seed(40)
tr <- sample(1:nrow(edit),2400)
train <- t.dta[tr,]
test <- t.dta[-tr,]
model <- lm(salary~.,data = train)
steps <- stepAIC(model,direction = "both",k = log(nrow(t.dta)))
summary(steps)
y.hat <- predict(steps,newdata = test)
MSE.BIC <- mean((test$salary-y.hat)**2)
sqrt(MSE.BIC)
summary(completeDataframe$salaryPercSalaryCap)
library(glmnet)
scaled <- scale(t.dta[,-c(58)])
scaled <- cbind(scaled,t.dta$salary)
tr.s <- scaled[tr,]
t.s <- scaled[-tr,]
lasso.model <- cv.glmnet(tr.s[,-c(58)],tr.s[,c(58)],alpha = 1 )
sqrt(lasso.model$cvm[lasso.model$lambda == lasso.model$lambda.1se])
# Plot lambdas
plot(log(lasso.model$lambda),sqrt(lasso.model$cvm),
main="LASSO CV (k=10)",xlab="log(lambda)",
ylab = "RMSE",col=4,type="b",cex.lab=1.2)
abline(v=log(lasso.model$lambda.1se),lty=2,col=2,lwd=2)
coefs.lasso <- predict(lasso.model, type = "coefficients", s = lasso.model$lambda.1se)
coefs.lasso
summary(lasso.model)
# Plot lambdas
plot(log(lasso.model$lambda),sqrt(lasso.model$cvm),
main="LASSO CV (k=10)",xlab="log(lambda)",
ylab = "RMSE",col=4,type="b",cex.lab=1.2)
abline(v=log(lasso.model$lambda.1se),lty=2,col=2,lwd=2)
coefs.lasso <- predict(lasso.model, type = "coefficients", s = lasso.model$lambda.1se)
coefs.lasso
ridge.model <- cv.glmnet(tr.s[,-c(58)],tr.s[,c(58)],alpha = 0)
sqrt(ridge.model$cvm[ridge.model$lambda == ridge.model$lambda.1se])
plot(log(ridge.model$lambda),sqrt(ridge.model$cvm),
main="LASSO CV (k=10)",xlab="log(lambda)",
ylab = "RMSE",col=4,type="b",cex.lab=1.2)
abline(v=log(ridge.model$lambda.1se),lty=2,col=2,lwd=2)
coefs.ridge <- predict(ridge.model, type = "coefficients", s = ridge.model$lambda.1se)
coefs.ridge
rm(list = c("edit","lasso.model","model.1","pos","MSE.BIC","posC",
"scaled","ridge.model","scaled.tr","t.s","t.dta","tr",
"train","y.hat","test","pos.1","steps","tr.s","model"))
set.seed(50)
tr <- sample(1:nrow(edit),2400)
train <- t.dta[tr,]
test <- t.dta[-tr,]
t.dta <- cbind(edit,completeDataframe$salaryPercSalaryCap)
colnames(t.dta)[length(colnames(t.dta))] = "salary"
set.seed(50)
tr <- sample(1:nrow(edit),2400)
train <- t.dta[tr,]
test <- t.dta[-tr,]
model <- lm(salary~.,data = train)
library(MASS)
# Dummy for position
pos <- factor(xDF$Pos)
model.1 <- model.matrix(~pos)[,-c(1)]
posC <- ifelse(xDF$Pos == "C",1,0)
pos.1 <- cbind(posC,model.1)
edit <- cbind(xDF,pos.1)[,-c(1)]
t.dta <- cbind(edit,completeDataframe$salaryPercSalaryCap)
colnames(t.dta)[length(colnames(t.dta))] = "salary"
set.seed(50)
tr <- sample(1:nrow(edit),2400)
train <- t.dta[tr,]
test <- t.dta[-tr,]
model <- lm(salary~.,data = train)
steps <- stepAIC(model,direction = "both",k = log(nrow(t.dta)))
summary(steps)
y.hat <- predict(steps,newdata = test)
MSE.BIC <- mean((test$salary-y.hat)**2)
sqrt(MSE.BIC)
completeDataframe$Player
completeDataframe$Player == "Kevin Durant"
which(completeDataframe$Player == "Kevin Durant")
completeDataframe[1725:1732,]
steps
?data.frame
completeDataframe$TRB
completeDataframe$X2P
completeDataframe$X2P[1725]
completeDataframe$X2P[1725:1732]
completeDataframe[1725:1732]
completeDataframe[1725:1732,]
steps
kevin.durant <- data.frame(c(28,70,70,6.2,8,2,9.3,1026,900,6,24,1.2,30.6,11,3.5,.9,6.4,0))
kevin.durant
case <- data.frame(c(28,70,70,6.2,8,2,9.3,1026,900,6,24,1.2,30.6,11,3.5,.9,6.4,0))
coefficients(steps)
colnames(case) <- colnames(steps)[-c(1)]
case
case
colnames(steps)
steps
colnames(coefficients(steps))
coefficients(steps)
?coefficients
colnames(case) <- c("Age","G","GS","AST","TRB","TOV","FGA","X2P","X2PA","FTA","AST_perc","STL_perc","USG_perc","OWS","DWS","DBPM","VORP","posPG")
length(case)
case
# Case Study
case <- data.frame()
case <- rbind(c(28,70,70,6.2,8,2,9.3,1026,900,6,24,1.2,30.6,11,3.5,.9,6.4,0))
colnames(case) <- c("Age","G","GS","AST","TRB","TOV","FGA","X2P","X2PA","FTA","AST_perc","STL_perc","USG_perc","OWS","DWS","DBPM","VORP","posPG")
case
y.hat <- predict(steps,newdata = case)
# Case Study
case <- data.frame(rbind(c(28,70,70,6.2,8,2,9.3,1026,900,6,24,1.2,30.6,11,3.5,.9,6.4,0)))
colnames(case) <- c("Age","G","GS","AST","TRB","TOV","FGA","X2P","X2PA","FTA","AST_perc","STL_perc","USG_perc","OWS","DWS","DBPM","VORP","posPG")
y.hat <- predict(steps,newdata = case)
y.hat
y.hat * 99093000
y.hat <- y.hat * 99093000 #convert back to salary
e <- y.hat - 25000000
e
which(completeDataframe$Player == "Kevin Durant")
completeDataframe[1732.]
completeDataframe[1732,]
# Kevin Durant's real salary in 2017 was 25000000
y.hat <- predict(steps,newdata = case)
#y.hat <- y.hat * 99093000 #convert back to salary
e <- y.hat - 0.2522883
e
which(completeDataframe$Player == "LeBron James")
completeDataframe[1909]
completeDataframe[1909,]
steps
case <- data.frame(rbind(c(28,70,70,6.2,513,2,9.3,1026,900,6,24,1.2,30.6,11,3.5,.9,6.4,0)))
colnames(case) <- c("Age","G","GS","AST","TRB","TOV","FGA","X2P","X2PA","FTA","AST_perc","STL_perc","USG_perc","OWS","DWS","DBPM","VORP","posPG")
# Kevin Durant's real salary in 2017 was 25000000
y.hat <- predict(steps,newdata = case)
#y.hat <- y.hat * 99093000 #convert back to salary
e <- y.hat - 0.2522883
e
case <- rbind(case,c(28,75,75,9.1,614,303,1344,612,1002,531,41.3,1.8,30,9.8,3,1.6,7.3,0))
y.hat <- predict(steps,newdata = case[,2])
case
case[,2]
y.hat <- predict(steps,newdata = case[2,])
y.hat
completeDataframe
which(completeDataframe$Player == "LeBron James")
completeDataframe$Salary[1909]
completeDataframe$salaryPercSalaryCap[1909]
e <- y.hat - .3359037
e
y.hat * 99093000
