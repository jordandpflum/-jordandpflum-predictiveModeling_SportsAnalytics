library(glmnet)
scaled <- scale(edit[,-c(1,3,49)]) # scale everything except TEAMS/POS to standard normal
scaled.data <- cbind(scaled,edit[,c(1,3)])
# LASSO
lasso.model <- glmnet(scaled.data[train,],edit[train,49],alpha=1)
?glmnet
?model.matrix
scaled.data <- matrix(cbind(scaled,edit[,c(1,3)]))
# LASSO
lasso.model <- glmnet(scaled.data[train,],edit[train,49],alpha=1)
scaled.data
scaled.data <- as.matrix(cbind(scaled,edit[,c(1,3)]))
# LASSO
lasso.model <- glmnet(scaled.data[train,],edit[train,49],alpha=1)
lasso.model
plot(lasso.model)
edit[,49]
which(colnames(edit) == "salary")
str(edit)
# LASSO
lasso.model <- glmnet(scaled.data[train,],edit[train,47],alpha=1)
ridge.model <- glmnet(scaled.data[train,],edit[train,47],alpha=1)
plot(lasso.model)
plot(ridge.model)
scaled.data[train,]
scaled <- scale(edit[,-c(1,3,47)]) # scale everything except TEAMS/POS to standard normal
scaled.data <- as.matrix(cbind(scaled,edit[,c(1,3)]))
scaled <- scale(edit[,-c(47)]) # scale everything except TEAMS/POS to standard normal
scaled
# LASSO
lasso.model <- glmnet(scaled.data[train,],edit[train,47],alpha=1)
ridge.model <- glmnet(scaled.data[train,],edit[train,47],alpha=0)
plot(lasso.model)
plot(ridge.model)
plot(lasso.model,xvar = c("lambda"))
plot(ridge.model, xvar = c("lambda"))
plot(lasso.model,xvar = c("lambda"))
pos
tm
pos[1]
pos$levels
# Write file
write(edit, file = "C:/Users/timot/Desktop/2017_sm_with_dummy.csv")
rm(list = ls())
data <- read.csv("C:/Users/timot/Documents/Github/predictiveModelingSportsAnalytics/2017_player_salary_and_metrics.csv", header = T)
# ONLY LOOK AT STATS and remove columns that have no info
edit <- data[,c(6:53,58)]
rownames(edit) <- data$player_id
# Create dummy variable for each team/position
tm <- factor(edit$Tm)
pos <- factor(edit$Pos)
dummies.1 <- model.matrix(~tm)
dummies.1 <- dummies.1[,-c(1)]
dummies.2 <- model.matrix(~pos)
dummies.2 <- dummies.2[,-c(1)]
edit$posC <- ifelse(edit[,1] == "C",1,0)
edit$tmATL <- ifelse(edit[,3] == "ATL",1,0)
edit <- cbind(edit,dummies.1)
edit <- cbind(edit,dummies.2)
edit <- edit[,-c(1,3)]
# Write file
write(edit, file = "C:/Users/timot/Desktop/2017_sm_with_dummy.csv")
write
?write
# Write file
write(edit, "C:/Users/timot/Desktop/2017_sm_with_dummy.csv")
head(edit)
edit <- matrix(edit[,-c(1,3)])
edit
edit <- as.matrix(edit[,-c(1,3)])
head(edit)
# ONLY LOOK AT STATS and remove columns that have no info
edit <- data[,c(6:53,58)]
rownames(edit) <- data$player_id
# Create dummy variable for each team/position
tm <- factor(edit$Tm)
pos <- factor(edit$Pos)
dummies.1 <- model.matrix(~tm)
dummies.1 <- dummies.1[,-c(1)]
dummies.2 <- model.matrix(~pos)
dummies.2 <- dummies.2[,-c(1)]
edit$posC <- ifelse(edit[,1] == "C",1,0)
edit$tmATL <- ifelse(edit[,3] == "ATL",1,0)
edit <- cbind(edit,dummies.1)
edit <- cbind(edit,dummies.2)
edit <- edit[,-c(1,3)]
View(edit)
edit <- matrix(edit[,-c(1,3)])
edit
# ONLY LOOK AT STATS and remove columns that have no info
edit <- data[,c(6:53,58)]
rownames(edit) <- data$player_id
# Create dummy variable for each team/position
tm <- factor(edit$Tm)
pos <- factor(edit$Pos)
dummies.1 <- model.matrix(~tm)
dummies.1 <- dummies.1[,-c(1)]
dummies.2 <- model.matrix(~pos)
dummies.2 <- dummies.2[,-c(1)]
edit$posC <- ifelse(edit[,1] == "C",1,0)
edit$tmATL <- ifelse(edit[,3] == "ATL",1,0)
edit <- cbind(edit,dummies.1)
edit <- cbind(edit,dummies.2)
edit <- edit[,-c(1,3)]
# Write file
write(edit, "C:/Users/timot/Desktop/2017_sm_with_dummy.csv")
# Write file
write.csv(edit, "C:/Users/timot/Desktop/2017_sm_with_dummy.csv")
rm(list = ls())
data <- read.csv("C:/Users/timot/Documents/Github/predictiveModelingSportsAnalytics/2017_player_salary_and_metrics.csv", header = T)
# ONLY LOOK AT STATS and remove columns that have no info
edit <- data[,c(6:53,58)]
rownames(edit) <- data$player_id
# Create dummy variable for each team/position
tm <- factor(edit$Tm)
pos <- factor(edit$Pos)
dummies.1 <- model.matrix(~tm)
dummies.1 <- dummies.1[,-c(1)]
dummies.2 <- model.matrix(~pos)
dummies.2 <- dummies.2[,-c(1)]
edit$posC <- ifelse(edit[,1] == "C",1,0)
edit$tmATL <- ifelse(edit[,3] == "ATL",1,0)
edit <- cbind(edit,dummies.1)
edit <- cbind(edit,dummies.2)
edit <- edit[,-c(1,3)]
# try to compensate for overfit
#set.seed(1)
set.seed(2)
#set.seed(3)
train <- sample(1:nrow(edit),size = 250)
train.data <- edit[train,]
test.data <- edit[-train,]
model.1 <- lm(salary~.,data = train.data)
library(MASS)
steps1 <- stepAIC(model.1, direction = "both", k = 2)
# Fit MLR model
final.AIC <- lm(salary~Age + GS + MP + TRB_perc + STL_perc + BLK_perc + USG_perc +
OWS + DWS + OBPM + BPM + VORP + FG + FGA + X3P + X3PA + X3P_perc +
FT + FTA + DRB + AST + PF + tmATL + tmGSW + tmMIA + tmPOR +
tmUTA + posPG + tmDEN, data = train.data)
# Has an adjusted R-squared of 0.62
summary(final.AIC)
y.hat <- predict(final.AIC,newdata = test.data)
MSE.AIC <- mean((test.data$salary-y.hat)**2)
MSE.AIC
# Has only 5 variables, all high significance.
# Age, GS, FGA, DRB, PF
steps2 <- stepAIC(model.1, direction = "both", k = log(nrow(edit)))
# Fit MLR model
final.BIC <- lm(salary~Age + GS + USG_perc + BPM + VORP + FTA + DRB + AST +
PF + tmPOR, data = train.data)
summary(final.BIC)
y.hat <- predict(final.BIC,newdata = test.data)
MSE.BIC <- mean((test.data$salary-y.hat)**2)
MSE.BIC
rm(list = ls())
data <- read.csv("C:/Users/timot/Documents/Github/predictiveModelingSportsAnalytics/2017_player_salary_and_metrics.csv", header = T)
# ONLY LOOK AT STATS and remove columns that have no info
edit <- data[,c(6:53,58)]
rownames(edit) <- data$player_id
# Create dummy variable for each team/position
tm <- factor(edit$Tm)
pos <- factor(edit$Pos)
dummies.1 <- model.matrix(~tm)
dummies.1 <- dummies.1[,-c(1)]
dummies.2 <- model.matrix(~pos)
dummies.2 <- dummies.2[,-c(1)]
edit$posC <- ifelse(edit[,1] == "C",1,0)
edit$tmATL <- ifelse(edit[,3] == "ATL",1,0)
edit <- cbind(edit,dummies.1)
edit <- cbind(edit,dummies.2)
edit <- edit[,-c(1,3)]
# try to compensate for overfit
#set.seed(1)
set.seed(2)
#set.seed(3)
train <- sample(1:nrow(edit),size = 250)
train.data <- edit[train,]
test.data <- edit[-train,]
model.1 <- lm(salary~.,data = train.data)
library(MASS)
steps1 <- stepAIC(model.1, direction = "both", k = 2)
# Fit MLR model
final.AIC <- lm(salary~Age + GS + MP + TRB_perc + STL_perc + BLK_perc + USG_perc +
OWS + DWS + OBPM + BPM + VORP + FG + FGA + X3P + X3PA + X3P_perc +
FT + FTA + DRB + AST + PF + tmATL + tmGSW + tmMIA + tmPOR +
tmUTA + posPG + tmDEN, data = train.data)
# Has an adjusted R-squared of 0.62
summary(final.AIC)
y.hat <- predict(final.AIC,newdata = test.data)
MSE.AIC <- mean((test.data$salary-y.hat)**2)
MSE.AIC
# Has only 5 variables, all high significance.
# Age, GS, FGA, DRB, PF
steps2 <- stepAIC(model.1, direction = "both", k = log(nrow(edit)))
# Fit MLR model
final.BIC <- lm(salary~Age + GS + USG_perc + BPM + VORP + FTA + DRB + AST +
PF + tmPOR, data = train.data)
summary(final.BIC)
y.hat <- predict(final.BIC,newdata = test.data)
MSE.BIC <- mean((test.data$salary-y.hat)**2)
MSE.BIC
sqrt(MSE.AIC)
sqrt(MSE.BIC)
stepAIC(model.1,direction = "forward", k = log(n))
stepAIC(model.1,direction = "forward", k = log(nrow(edit)))
null <- lm(salary~1,data = train.data)
null
summary(null)
step(null,direction = "forward",k = log(nrow(edit)))
stepAIC(null,direction = "forward",k = log(nrow(edit)))
x <- stepAIC(null,direction = "forward",k = log(nrow(edit)))
x <- stepAIC(null,direction = "forward",k = 2)
x <- stepAIC(model.1,direction = "backward",k = 2)
y <- lm(salary~Age + GS + MP + TRB_perc + STL_perc + BLK_perc + USG_perc +
OWS + DWS + OBPM + BPM + VORP + FG + FGA + X3P + X3PA + X3P_perc +
FT + FTA + DRB + AST + PF + tmATL + tmGSW + tmMIA + tmPOR +
tmSAC + tmUTA + posPG, data = train.data)
summary(y)
hats <- predict(y,newdata = test.data)
hats
MSE <- mean((test.data$salary - hats)**2)
MSE
sqrt(MSE)
summary(y)
steps3 <- stepAIC(model.1, direction = "backward", k = log(nrow(edit)))
steps3 <- stepAIC(model.1, direction = "backward", k = log(nrow(edit)))
steps3 <- stepAIC(model.1, direction = "forward", k = log(nrow(edit)))
steps3 <- stepAIC(null, direction = "forward", k = log(nrow(edit)))
steps3 <- stepAIC(model.1, direction = "forward", k = 2)
steps3 <- stepAIC(model.1, direction = "backward", k = 2)
rm(list = ls())
data <- read.csv("C:/Users/timot/Documents/Github/predictiveModelingSportsAnalytics/2017_player_salary_and_metrics.csv", header = T)
# ONLY LOOK AT STATS and remove columns that have no info
edit <- data[,c(6:53,58)]
rownames(edit) <- data$player_id
# Create dummy variable for each team/position
tm <- factor(edit$Tm)
pos <- factor(edit$Pos)
dummies.1 <- model.matrix(~tm)
dummies.1 <- dummies.1[,-c(1)]
dummies.2 <- model.matrix(~pos)
dummies.2 <- dummies.2[,-c(1)]
edit$posC <- ifelse(edit[,1] == "C",1,0)
edit$tmATL <- ifelse(edit[,3] == "ATL",1,0)
edit <- cbind(edit,dummies.1)
edit <- cbind(edit,dummies.2)
edit <- edit[,-c(1,3)]
# try to compensate for overfit
#set.seed(1)
set.seed(2)
#set.seed(3)
train <- sample(1:nrow(edit),size = 250)
train.data <- edit[train,]
test.data <- edit[-train,]
model.1 <- lm(salary~.,data = train.data)
library(MASS)
steps1 <- stepAIC(model.1, direction = "both", k = 2)
# Fit MLR model
final.AIC <- lm(salary~Age + GS + MP + TRB_perc + STL_perc + BLK_perc + USG_perc +
OWS + DWS + OBPM + BPM + VORP + FG + FGA + X3P + X3PA + X3P_perc +
FT + FTA + DRB + AST + PF + tmATL + tmGSW + tmMIA + tmPOR +
tmUTA + posPG + tmDEN, data = train.data)
# Has an adjusted R-squared of 0.62
summary(final.AIC)
y.hat <- predict(final.AIC,newdata = test.data)
MSE.AIC <- mean((test.data$salary-y.hat)**2)
sqrt(MSE.AIC)
# Has only 5 variables, all high significance.
# Age, GS, FGA, DRB, PF
steps2 <- stepAIC(model.1, direction = "both", k = log(nrow(edit)))
# Fit MLR model
final.BIC <- lm(salary~Age + GS + USG_perc + BPM + VORP + FTA + DRB + AST +
PF + tmPOR, data = train.data)
summary(final.BIC)
# try to compensate for overfit
set.seed(1)
#set.seed(2)
#set.seed(3)
train <- sample(1:nrow(edit),size = 250)
train.data <- edit[train,]
test.data <- edit[-train,]
model.1 <- lm(salary~.,data = train.data)
library(MASS)
steps1 <- stepAIC(model.1, direction = "both", k = 2)
# Fit MLR model
final.AIC <- lm(salary~Age + GS + MP + TRB_perc + STL_perc + BLK_perc + USG_perc +
OWS + DWS + OBPM + BPM + VORP + FG + FGA + X3P + X3PA + X3P_perc +
FT + FTA + DRB + AST + PF + tmATL + tmGSW + tmMIA + tmPOR +
tmUTA + posPG + tmDEN, data = train.data)
# Has an adjusted R-squared of 0.62
summary(final.AIC)
y.hat <- predict(final.AIC,newdata = test.data)
MSE.AIC <- mean((test.data$salary-y.hat)**2)
sqrt(MSE.AIC)
# Has only 5 variables, all high significance.
# Age, GS, FGA, DRB, PF
steps2 <- stepAIC(model.1, direction = "both", k = log(nrow(edit)))
# Fit MLR model
final.BIC <- lm(salary~Age + GS + USG_perc + BPM + VORP + FTA + DRB + AST +
PF + tmPOR, data = train.data)
summary(final.BIC)
y.hat <- predict(final.BIC,newdata = test.data)
# Has only 5 variables, all high significance.
# Age, GS, FGA, DRB, PF
steps2 <- stepAIC(model.1, direction = "both", k = log(nrow(edit)))
summary(final.BIC)
summary(steps2)
y.hat <- predict(steps2,newdata = test.data)
MSE.BIC <- mean((test.data$salary-y.hat)**2)
sqrt(MSE.BIC)
# try to compensate for overfit
#set.seed(1)
#set.seed(2)
set.seed(3)
train <- sample(1:nrow(edit),size = 250)
train.data <- edit[train,]
test.data <- edit[-train,]
model.1 <- lm(salary~.,data = train.data)
library(MASS)
steps1 <- stepAIC(model.1, direction = "both", k = 2)
# Fit MLR model
final.AIC <- lm(salary~Age + GS + MP + TRB_perc + STL_perc + BLK_perc + USG_perc +
OWS + DWS + OBPM + BPM + VORP + FG + FGA + X3P + X3PA + X3P_perc +
FT + FTA + DRB + AST + PF + tmATL + tmGSW + tmMIA + tmPOR +
tmUTA + posPG + tmDEN, data = train.data)
# Has an adjusted R-squared of 0.62
summary(final.AIC)
y.hat <- predict(final.AIC,newdata = test.data)
MSE.AIC <- mean((test.data$salary-y.hat)**2)
sqrt(MSE.AIC)
# Has only 5 variables, all high significance.
# Age, GS, FGA, DRB, PF
steps2 <- stepAIC(model.1, direction = "both", k = log(nrow(edit)))
# Fit MLR model
final.BIC <- lm(salary~Age + GS + USG_perc + BPM + VORP + FTA + DRB + AST +
PF + tmPOR, data = train.data)
summary(final.BIC)
y.hat <- predict(final.BIC,newdata = test.data)
# try to compensate for overfit
#set.seed(1)
#set.seed(2)
#set.seed(3)
set.seed(4)
train <- sample(1:nrow(edit),size = 250)
train.data <- edit[train,]
test.data <- edit[-train,]
model.1 <- lm(salary~.,data = train.data)
library(MASS)
steps1 <- stepAIC(model.1, direction = "both", k = 2)
# Fit MLR model
final.AIC <- lm(salary~Age + GS + MP + TRB_perc + STL_perc + BLK_perc + USG_perc +
OWS + DWS + OBPM + BPM + VORP + FG + FGA + X3P + X3PA + X3P_perc +
FT + FTA + DRB + AST + PF + tmATL + tmGSW + tmMIA + tmPOR +
tmUTA + posPG + tmDEN, data = train.data)
# Has an adjusted R-squared of 0.62
summary(final.AIC)
y.hat <- predict(final.AIC,newdata = test.data)
MSE.AIC <- mean((test.data$salary-y.hat)**2)
sqrt(MSE.AIC)
# Has only 5 variables, all high significance.
# Age, GS, FGA, DRB, PF
steps2 <- stepAIC(model.1, direction = "both", k = log(nrow(edit)))
# Fit MLR model
final.BIC <- lm(salary~Age + GS + USG_perc + BPM + VORP + FTA + DRB + AST +
PF + tmPOR, data = train.data)
summary(final.BIC)
y.hat <- predict(final.BIC,newdata = test.data)
MSE.BIC <- mean((test.data$salary-y.hat)**2)
sqrt(MSE.BIC)
# try to compensate for overfit
#set.seed(1)
#set.seed(2)
#set.seed(3)
#set.seed(4)
set.seed(5)
train <- sample(1:nrow(edit),size = 250)
train.data <- edit[train,]
test.data <- edit[-train,]
model.1 <- lm(salary~.,data = train.data)
library(MASS)
steps1 <- stepAIC(model.1, direction = "both", k = 2)
# Fit MLR model
final.AIC <- lm(salary~Age + GS + MP + TRB_perc + STL_perc + BLK_perc + USG_perc +
OWS + DWS + OBPM + BPM + VORP + FG + FGA + X3P + X3PA + X3P_perc +
FT + FTA + DRB + AST + PF + tmATL + tmGSW + tmMIA + tmPOR +
tmUTA + posPG + tmDEN, data = train.data)
# Has an adjusted R-squared of 0.62
summary(final.AIC)
y.hat <- predict(final.AIC,newdata = test.data)
MSE.AIC <- mean((test.data$salary-y.hat)**2)
sqrt(MSE.AIC)
# Has only 5 variables, all high significance.
# Age, GS, FGA, DRB, PF
steps2 <- stepAIC(model.1, direction = "both", k = log(nrow(edit)))
# Fit MLR model
final.BIC <- lm(salary~Age + GS + USG_perc + BPM + VORP + FTA + DRB + AST +
PF + tmPOR, data = train.data)
summary(final.BIC)
y.hat <- predict(final.BIC,newdata = test.data)
MSE.BIC <- mean((test.data$salary-y.hat)**2)
sqrt(MSE.BIC)
rm(list = ls())
data <- read.csv("C:/Users/timot/Documents/Github/predictiveModelingSportsAnalytics/2017_player_salary_and_metrics.csv", header = T)
summary(data$salary)
rm(list = ls())
data <- read.csv("C:/Users/timot/Documents/Github/predictiveModelingSportsAnalytics/2017_player_salary_and_metrics.csv", header = T)
# ONLY LOOK AT STATS and remove columns that have no info
edit <- data[,c(6:53,58)]
rownames(edit) <- data$player_id
# Create dummy variable for each team/position
tm <- factor(edit$Tm)
pos <- factor(edit$Pos)
dummies.1 <- model.matrix(~tm)
dummies.1 <- dummies.1[,-c(1)]
dummies.2 <- model.matrix(~pos)
dummies.2 <- dummies.2[,-c(1)]
edit$posC <- ifelse(edit[,1] == "C",1,0)
edit$tmATL <- ifelse(edit[,3] == "ATL",1,0)
edit <- cbind(edit,dummies.1)
edit <- cbind(edit,dummies.2)
edit <- edit[,-c(1,3)]
# try to compensate for overfit
#set.seed(1)
#set.seed(2)
#set.seed(3)
#set.seed(4)
set.seed(5)
train <- sample(1:nrow(edit),size = 250)
train.data <- edit[train,]
test.data <- edit[-train,]
model.1 <- lm(salary~.,data = train.data)
library(MASS)
steps1 <- stepAIC(model.1, direction = "both", k = 2)
# Fit MLR model
final.AIC <- lm(salary~Age + GS + MP + TRB_perc + STL_perc + BLK_perc + USG_perc +
OWS + DWS + OBPM + BPM + VORP + FG + FGA + X3P + X3PA + X3P_perc +
FT + FTA + DRB + AST + PF + tmATL + tmGSW + tmMIA + tmPOR +
tmUTA + posPG + tmDEN, data = train.data)
# Has an adjusted R-squared of 0.62
summary(final.AIC)
y.hat <- predict(final.AIC,newdata = test.data)
MSE.AIC <- mean((test.data$salary-y.hat)**2)
sqrt(MSE.AIC)
# Has only 5 variables, all high significance.
# Age, GS, FGA, DRB, PF
steps2 <- stepAIC(model.1, direction = "both", k = log(nrow(edit)))
# Fit MLR model
final.BIC <- lm(salary~Age + GS + USG_perc + BPM + VORP + FTA + DRB + AST +
PF + tmPOR, data = train.data)
summary(final.BIC)
y.hat <- predict(final.BIC,newdata = test.data)
MSE.BIC <- mean((test.data$salary-y.hat)**2)
sqrt(MSE.BIC)
library(kknn)
?kknn
rm(list=ls())
# Dataframe Creation
source("DataWrangling/createCompleteDataframe.R")
# Load Data (Player Salary)
playerSalaryData<-read.csv("Data/PlayerSalary_Season/salaries_1985to2018.csv", stringsAsFactors = FALSE)
# Load Data (Player Season Metrics)
playerSeasonMetricsData<-read.csv("Data/PlayerMetrics_Season/player_metric_season.csv", stringsAsFactors = FALSE)
completeDataframe <- createCompleteDataframeTotal(playerSalaryData=playerSalaryData,
playerSeasonMetricsData=playerSeasonMetricsData,
year_start=2010,
year_end=2017)
setwd("C:/Users/timot/Documents/GitHub/predictiveModelingSportsAnalytics/")
# Dataframe Creation
source("DataWrangling/createCompleteDataframe.R")
# Load Data (Player Salary)
playerSalaryData<-read.csv("Data/PlayerSalary_Season/salaries_1985to2018.csv", stringsAsFactors = FALSE)
# Load Data (Player Season Metrics)
playerSeasonMetricsData<-read.csv("Data/PlayerMetrics_Season/player_metric_season.csv", stringsAsFactors = FALSE)
completeDataframe <- createCompleteDataframeTotal(playerSalaryData=playerSalaryData,
playerSeasonMetricsData=playerSeasonMetricsData,
year_start=2010,
year_end=2017)
# Grouping by Age.
source("Classification/createAgeGroupingDataframe.R")
ageGroupedDataframe_18_22 <- createAgeGroupingDataframe(completeDataframe, ageGroup='18 - 22')
ageGroupedDataframe_23_26 <- createAgeGroupingDataframe(completeDataframe, ageGroup='23 - 26')
ageGroupedDataframe_27_30 <- createAgeGroupingDataframe(completeDataframe, ageGroup='27 - 30')
ageGroupedDataframe_31_35 <- createAgeGroupingDataframe(completeDataframe, ageGroup='31 - 35')
ageGroupedDataframe_over35 <- createAgeGroupingDataframe(completeDataframe, ageGroup='>35')
# Create X-DF
source("DataWrangling/createPartialDataframe.R")
variables = c("Pos", "Age", "G", "GS", "MP", "PTS", "AST", "TRB", "ORB", "DRB",
"STL", "BLK", "TOV", "PF", "FG", "FGA", "X2P", "X2PA", "X3P",
"FT", "FTA", "PER", "ORB_perc", "DRB_perc", "TRB_perc", "AST_perc",
"STL_perc", "BLK_perc", "TOV_perc", "USG_perc", "OWS", "DWS",
"WS", "WS_48", "OBPM", "DBPM", "BPM", "VORP", "TSA", "TS_perc",
"X3P_perc", "X2P_perc", "eFG_perc", "FT_perc")
xDF = createParitalDataframe(df = completeDataframe, colNames = variables)
colnames(xDF) <- variables
# Create Y-DF
variables = c("Salary")
yDF = createParitalDataframe(df = completeDataframe, colNames = variables)
summary(yDF)
boxplot(yDF)
plot(range(length((yDF))),yDF)
# Variable Selection
source("Prediction/predictions_based_on_position.R")
player_csv <- completeDataframe
player_csv[,c( "Tm", "Player", "Salary")] <- list(NULL)
Perform_Linear_regression(player_csv,"Overall")
# Variable Selection
source("VariableSelection/variable_selectionfunction.R")
Perform_penaltyreg(player_csv,a = 1)
Perform_penaltyreg(player_csv,a = 0)
Perform_Linear_regression(player_csv,"Overall")
3126336/99093000
